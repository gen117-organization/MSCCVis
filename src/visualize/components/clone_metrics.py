import logging
import os

from dash import html, dcc
import pandas as pd

from ..utils import get_local_snippet
from ..constants import DetectionMethod
from collections import Counter

logger = logging.getLogger(__name__)

def calculate_unique_pair_count_for_clone(clone_df):
    """ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒšã‚¢æ•°ã‚’è¨ˆç®—ã™ã‚‹"""
    if clone_df is None or clone_df.empty:
        return 0

    # é‡è¤‡é™¤å»ã®ãŸã‚ã®ã‚­ãƒ¼ã‚’ä½œæˆ
    df_temp = clone_df.copy()
    df_temp["clone_key"] = (
        df_temp["clone_id"].astype(str)
        + "|"
        + df_temp["file_path_x"].str.split("/").str[-1]
        + "|"
        + df_temp["start_line_x"].astype(str)
        + "-"
        + df_temp["end_line_x"].astype(str)
        + "|"
        + df_temp["file_path_y"].str.split("/").str[-1]
        + "|"
        + df_temp["start_line_y"].astype(str)
        + "-"
        + df_temp["end_line_y"].astype(str)
    )

    # coord_pairåˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    if "coord_pair" not in df_temp.columns:
        df_temp["coord_pair"] = (
            df_temp["file_id_y"].astype(str) + "_" + df_temp["file_id_x"].astype(str)
        )

    # é‡è¤‡é™¤å»ã—ã¦æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    return len(df_temp.drop_duplicates(subset=["coord_pair", "clone_key"]))


def calculate_cross_service_metrics(df):
    """ã‚¯ãƒ­ãƒ¼ãƒ³ã®å¤šã‚µãƒ¼ãƒ“ã‚¹è·¨ã‚Šåº¦ã‚’åˆ†æã™ã‚‹"""
    if df is None or df.empty:
        return {}, 0, {}

    # å…¨ã‚µãƒ¼ãƒ“ã‚¹æ•°ã‚’è¨ˆç®—
    services_x = set(df["service_x"].unique())
    services_y = set(df["service_y"].unique())
    total_services = len(services_x.union(services_y))

    # å„ã‚¯ãƒ­ãƒ¼ãƒ³IDãŒè·¨ã‚‹ã‚µãƒ¼ãƒ“ã‚¹æ•°ã‚’è¨ˆç®—
    clone_metrics = {}
    for clone_id in df["clone_id"].unique():
        clone_rows = df[df["clone_id"] == clone_id]
        services_x = set(clone_rows["service_x"].unique())
        services_y = set(clone_rows["service_y"].unique())
        all_clone_services = services_x.union(services_y)

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒšã‚¢æ•°ã‚’è¨ˆç®—
        unique_pair_count = calculate_unique_pair_count_for_clone(clone_rows)

        # Co-modifiedãƒšã‚¢æ•°ã‚’è¨ˆç®—
        comodified_count = 0
        if "comodified" in clone_rows.columns:
            comodified_count = len(
                clone_rows[clone_rows["comodified"].isin([1, True, "1", "True"])]
            )

        # Code Typeã®å†…è¨³ã‚’è¨ˆç®—
        code_types = Counter()
        is_mixed = False
        if "file_type_x" in clone_rows.columns and "file_type_y" in clone_rows.columns:
            # Mixedåˆ¤å®š: Test vs Product (Test vs Non-Test)
            is_test_x = clone_rows["file_type_x"] == "test"
            is_test_y = clone_rows["file_type_y"] == "test"
            mixed_rows = clone_rows[is_test_x != is_test_y]

            if not mixed_rows.empty:
                is_mixed = True

            # é›†è¨ˆã¯xå´ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹ï¼ˆä»£è¡¨å€¤ï¼‰
            code_types.update(clone_rows["file_type_x"])
        elif "file_type_x" in clone_rows.columns:
            code_types.update(clone_rows["file_type_x"])

        # Detection Method (ã‚‚ã—æ··åœ¨ã—ã¦ã„ã‚‹å ´åˆ)
        methods = set()
        if "detection_method" in clone_rows.columns:
            methods.update(clone_rows["detection_method"].unique())
        elif "clone_type" in clone_rows.columns:  # fallback
            methods.update(clone_rows["clone_type"].unique())

        clone_metrics[clone_id] = {
            "service_count": len(all_clone_services),
            "services": list(all_clone_services),
            "pair_count": unique_pair_count,  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒšã‚¢æ•°ã‚’ä½¿ç”¨
            "total_pair_count": len(clone_rows),  # å…ƒã®é‡è¤‡å«ã‚€æ•°ã‚‚ä¿æŒ
            "comodified_count": comodified_count,
            "code_types": dict(code_types),
            "is_mixed": is_mixed,
            "methods": list(methods),
            "inter_service_pairs": len(clone_rows[clone_rows["clone_type"] == "inter"]),
            "file_paths": list(
                set(
                    clone_rows["file_path_x"].tolist()
                    + clone_rows["file_path_y"].tolist()
                )
            ),
        }

    # ã‚µãƒ¼ãƒ“ã‚¹è·¨ã‚Šåº¦ã®åˆ†å¸ƒ
    service_count_distribution = Counter(
        [metrics["service_count"] for metrics in clone_metrics.values()]
    )

    return clone_metrics, total_services, service_count_distribution


def generate_cross_service_filter_options(clone_stats):
    """
    ã‚¯ãƒ­ãƒ¼ãƒ³IDã”ã¨ã®çµ±è¨ˆæƒ…å ±ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
    clone_stats: list of dict {'clone_id': id, 'service_count': count, 'code_type': type}
    Sorted by service_count DESC
    """
    options = [{"label": "Show All Clones", "value": "all"}]

    for stat in clone_stats:
        # Improved formatting using symbols for readability and spacing
        label = f"ğŸ†” {stat['clone_id']}   ğŸŒ {stat['service_count']} Services   ğŸ·ï¸ {stat['code_type']}"
        options.append({"label": label, "value": stat["clone_id"]})

    return options


def get_github_base_url(project):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã¨åŒã˜æ–¹æ³•ã§GitHubãƒ™ãƒ¼ã‚¹URLã‚’å–å¾—ã™ã‚‹"""
    from ..data_loader import load_project_summary

    summary_data = load_project_summary()
    if summary_data and project in summary_data.get("projects", {}):
        project_info = summary_data["projects"][project]
        if "metadata" in project_info:
            metadata = project_info["metadata"]
            return metadata.get("url", f"https://github.com/{project}")

    # fallback: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰URLã‚’æ§‹ç¯‰
    return f"https://github.com/{project}"


def generate_github_file_url(project, file_path, start_line=None, end_line=None):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã¨æ•´åˆæ€§ã®ã‚ã‚‹GitHubãƒ•ã‚¡ã‚¤ãƒ«URLã‚’ç”Ÿæˆã™ã‚‹"""
    if not project or not file_path:
        return None

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã¨åŒã˜æ–¹æ³•ã§ãƒ™ãƒ¼ã‚¹URLã‚’å–å¾—
    github_base = get_github_base_url(project)

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å…ˆé ­ã®/ã‚’å‰Šé™¤
    clean_file_path = file_path.lstrip("/")

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ–ãƒ©ãƒ³ãƒã‚’ä½¿ç”¨ï¼ˆé€šå¸¸ã¯ main ã¾ãŸã¯ masterï¼‰
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼JSONã« branch æƒ…å ±ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
    from ..data_loader import load_project_summary

    branch = "main"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    summary_data = load_project_summary()
    if summary_data and project in summary_data.get("projects", {}):
        project_info = summary_data["projects"][project]
        if "metadata" in project_info:
            metadata = project_info["metadata"]
            branch = metadata.get("default_branch", "master")

    # ãƒ•ã‚¡ã‚¤ãƒ«URLã‚’æ§‹ç¯‰
    file_url = f"{github_base}/blob/{branch}/{clean_file_path}"

    # è¡Œç•ªå·ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡Œç¯„å›²ã‚’è¿½åŠ 
    if start_line is not None:
        if end_line is not None and end_line != start_line:
            file_url += f"#L{start_line}-L{end_line}"
        else:
            file_url += f"#L{start_line}"

    return file_url


def find_overlapping_clones(df, click_x, click_y):
    """æŒ‡å®šã•ã‚ŒãŸåº§æ¨™ã«ã‚ã‚‹ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’æ¤œç´¢ã™ã‚‹"""
    # æ•£å¸ƒå›³ã¯ x=file_id_y, y=file_id_x ã§æç”»ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€
    # coord_pair (file_id_y_file_id_x) ã¨ä¸€è‡´ã•ã›ã‚‹ã«ã¯ click_x_click_y ã®é †ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
    coord_pair = f"{int(click_x)}_{int(click_y)}"

    # coord_pairåˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    if "coord_pair" not in df.columns:
        df["coord_pair"] = (
            df["file_id_y"].astype(str) + "_" + df["file_id_x"].astype(str)
        )

    # è©²å½“ã™ã‚‹åº§æ¨™ã®ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’æ¤œç´¢
    overlapping_indices = df[df["coord_pair"] == coord_pair].index.tolist()
    return overlapping_indices


def build_clone_selector(overlapping_indices, df):
    """é‡è¤‡ã‚¯ãƒ­ãƒ¼ãƒ³é¸æŠç”¨ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’ç”Ÿæˆã™ã‚‹"""
    if len(overlapping_indices) <= 1:
        return html.Div()  # é‡è¤‡ãŒãªã„å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

    clone_count = len(overlapping_indices)
    options = []
    clone_data = []  # ã‚½ãƒ¼ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
    seen_clones = set()  # é‡è¤‡é™¤å»ç”¨

    # ã¾ãšå…¨ã¦ã®ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€é‡è¤‡ã‚’é™¤å»
    for i, idx in enumerate(overlapping_indices):
        row = df.loc[idx]
        file_x = row.get("file_path_x", "Unknown").split("/")[-1]
        file_y = row.get("file_path_y", "Unknown").split("/")[-1]
        lines_x = f"{row.get('start_line_x', 0)}-{row.get('end_line_x', 0)}"
        lines_y = f"{row.get('start_line_y', 0)}-{row.get('end_line_y', 0)}"
        clone_id = row.get("clone_id", idx)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚­ãƒ¼ã‚’ä½œæˆï¼ˆclone_id + ãƒ•ã‚¡ã‚¤ãƒ« + è¡Œç¯„å›²ï¼‰
        clone_key = f"{clone_id}|{file_x}|{lines_x}|{file_y}|{lines_y}"

        if clone_key not in seen_clones:
            seen_clones.add(clone_key)
            clone_data.append(
                {
                    "clone_id": clone_id,
                    "idx": idx,
                    "file_x": file_x,
                    "file_y": file_y,
                    "lines_x": lines_x,
                    "lines_y": lines_y,
                    "clone_key": clone_key,
                }
            )

    # é‡è¤‡é™¤å»å¾Œã®æ•°ãŒ1ä»¥ä¸‹ã®å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„
    if len(clone_data) <= 1:
        return html.Div()

    # clone_idã”ã¨ã®å€‹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆé‡è¤‡é™¤å»å¾Œï¼‰
    from collections import Counter

    clone_id_counts = Counter(data["clone_id"] for data in clone_data)

    # ãƒšã‚¢æ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤šã„é †ã€åŒã˜ãƒšã‚¢æ•°ã®å ´åˆã¯clone_idã§ã‚½ãƒ¼ãƒˆï¼‰
    clone_data.sort(key=lambda x: (-clone_id_counts[x["clone_id"]], x["clone_id"]))

    # ã‚½ãƒ¼ãƒˆå¾Œã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆï¼ˆclone_idã®å€‹æ•°æƒ…å ±ã‚’è¿½åŠ ï¼‰
    for data in clone_data:
        clone_id = data["clone_id"]
        count = clone_id_counts[clone_id]
        count_info = f" ({count} pairs)" if count > 1 else ""
        label = f"Clone ID {clone_id}: {data['file_x']}[{data['lines_x']}] â†” {data['file_y']}[{data['lines_y']}]{count_info}"
        options.append({"label": label, "value": data["idx"]})

    # é‡è¤‡é™¤å»ã®æƒ…å ±ã‚’è¡¨ç¤º
    removed_count = clone_count - len(clone_data)
    header_text = (
        f"{len(clone_data)} overlapping clones found. Select a clone to display:"
    )
    if removed_count > 0:
        header_text += f" ({removed_count} duplicates removed)"

    return html.Div(
        [
            html.H6(header_text, style={"margin-bottom": "10px"}),
            dcc.Dropdown(
                id="clone-dropdown",
                options=options,
                value=clone_data[0]["idx"],  # ã‚½ãƒ¼ãƒˆå¾Œã®æœ€åˆã®ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’é¸æŠ
                clearable=False,
                style={
                    "width": "100%",
                    "minWidth": "600px",
                    "maxWidth": "900px",
                    "margin-bottom": "15px",
                },  # å¹…ã‚’èª¿æ•´
            ),
        ],
        style={
            "background": "white",
            "padding": "15px",
            "border-radius": "8px",
            "margin-bottom": "5px",
        },
    )


